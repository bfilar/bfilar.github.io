<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>BabbelPhish | Bobby Filar</title> <meta name="author" content="Bobby Filar"> <meta name="description" content="Accelerating Adoption of Domain-Specific Languages with Large Language Models"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bfilar.github.io/projects/babbelphish/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Bobby </span>Filar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/papers/">papers</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">BabbelPhish</h1> <p class="post-description">Accelerating Adoption of Domain-Specific Languages with Large Language Models</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/babbelphish-480.webp 480w, /assets/img/babbelphish-800.webp 800w, /assets/img/babbelphish-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/babbelphish.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="BabbelPhish" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Natural Language to Domain Specific Language </div> <p><strong>BabbelPhising</strong> Github Repo: <a href="https://github.com/bfilar/babbelphish" title="GitHub Repo" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a></p> <h2 id="getting-started">Getting Started</h2> <p>To install the required libraries, use:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install -r requirements.txt
</code></pre></div></div> <p>Getting Started Clone the repository:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/bfilar/babbelphish.git
cd babbelphish
</code></pre></div></div> <p>Next, you need to set your OpenAI API key as an environment variable:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export OPENAI_API_KEY='your-api-key-here'
</code></pre></div></div> <h2 id="fine-tuning-a-model-with-finetunepy">Fine-Tuning a Model with finetune.py</h2> <p>The finetune.py script provides a complete workflow to fine-tune an OpenAI model on a custom dataset. In this specific use case, we are fine-tuning the Curie model on the Sublime Security BabbelPhish dataset, but the code can be easily adapted to other datasets and models.</p> <h3 id="usage">Usage</h3> <p>Set the OpenAI API Key: Ensure your OpenAI API key is set as an environment variable or modify the script to include it directly.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export OPENAI_API_KEY='your-api-key-here'
</code></pre></div></div> <ol> <li>Load and Prepare Data: The script loads the dataset and preprocesses the prompts and completions.</li> <li>Convert to JSONL and Upload: The data is converted to JSONL format and uploaded to OpenAI.</li> <li>Fine-Tune the Model: The script initiates the fine-tuning process using the uploaded data.</li> <li>Monitor Fine-Tuning Events: You can track the progress and events of the fine-tuning process through the OpenAI Dashboard or modify the script to print events to the console.</li> </ol> <p>To run the script, simply execute:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python finetune.py
</code></pre></div></div> <h2 id="mql-tokenizer-webapp">MQL Tokenizer Webapp</h2> <p>The MQL Tokenizer Webapp is a Flask-based web application that allows users to input a piece of text and tokenize it using different tokenizers, including GPT-2, GPT-3, GPT-4, and a custom tokenizer trained on MQL dataset. The tokenization results, alongside some useful tokenizer metrics, are displayed in a user-friendly way.</p> <h3 id="setup--installation">Setup &amp; Installation</h3> <p>To get started, you will need to install the required packages. This can be done by running:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install -r requirements.txt
</code></pre></div></div> <p>Next, navigate to the webapp directory:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd tokenizer_webapp
</code></pre></div></div> <p>Then, start the Flask application:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python app.py
</code></pre></div></div> <p>Your application should now be running at http://127.0.0.1:5000/.</p> <h3 id="usage-1">Usage</h3> <p>To use the webapp, simply enter a piece of text into the text area and select the tokenizer you would like to use. Click the ‘Submit’ button to tokenize the text. The results will be displayed below, showing each token, its position in the sentence, and its corresponding color. You can also see the total number of tokens, unique tokens, and average tokens per sentence.</p> <p>To switch to a different tokenizer, simply select the desired tokenizer and click ‘Submit’ again. You can also reset the form by clicking the ‘Reset’ button.</p> <p>Again, you will want to customize this to fit your specific application, including providing more detailed instructions or screenshots if necessary.</p> <h2 id="training-a-custom-gpt-tokenizer">Training a Custom GPT Tokenizer</h2> <p>You can train a custom GPT tokenizer on your dataset by using the <code class="language-plaintext highlighter-rouge">train_tokenizer.py</code> script. This script reads a dataset from a JSONL file, trains a new tokenizer based on a base model, and saves the new tokenizer to a directory of your choice.</p> <h3 id="usage-2">Usage</h3> <p>The <code class="language-plaintext highlighter-rouge">train_tokenizer.py</code> script accepts the following command-line arguments:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">--base_model</code>: The model to use as the base for training the new tokenizer. (Default: <code class="language-plaintext highlighter-rouge">"gpt2"</code>)</li> <li> <code class="language-plaintext highlighter-rouge">--dataset_path</code>: The path to the dataset file in JSONL format.</li> <li> <code class="language-plaintext highlighter-rouge">--vocab_size</code>: The vocabulary size for the new tokenizer. (Default: <code class="language-plaintext highlighter-rouge">35000</code>)</li> <li> <code class="language-plaintext highlighter-rouge">--output_dir</code>: The directory where the new tokenizer will be saved. (Default: <code class="language-plaintext highlighter-rouge">"mql-tokenizer"</code>)</li> </ul> <h3 id="example">Example</h3> <p>To train a tokenizer from the gpt2 model using a dataset in <code class="language-plaintext highlighter-rouge">data/</code> and a vocabulary size of 35000, saving the result in mql-tokenizer, you would run:</p> <pre><code class="language-{bash}">python train_tokenizer.py --base_model gpt2 --dataset_path data/mql_prompts_prepared.jsonl --vocab_size 35000 --output_dir mql-tokenizer
</code></pre> <p>After the script finishes, the new tokenizer will be saved in the mql-tokenizer directory. You can then use this tokenizer for other tasks.</p> <h2 id="tokenizer-metrics">Tokenizer Metrics</h2> <p>The Tokenizer Metrics script allows you to analyze the performance and characteristics of different tokenizers. It calculates various metrics such as Out-of-Vocabulary (OOV) rate, tokenization granularity, information loss, token type ratio, and reversibility. This tool is especially useful when comparing different tokenizers or fine-tuning a custom tokenizer.</p> <h3 id="usage-3">Usage</h3> <p>The Tokenizer Metrics script can be run from the command line as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python tokenizer_metrics.py --tokenizer_path "tokenizer_directory" --dataset_path "data/mql_prompts_prepared.jsonl"
</code></pre></div></div> <p>In the above command, replace “tokenizer_directory” with the path to your tokenizer and “data/mql_prompts_prepared.jsonl” with the path to your JSONL dataset.</p> <p>The script will then output the calculated metrics to the console, for example:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OOV rate: 0.30
Tokenization granularity: 0.37
Information loss: 0.00
Token type ratio: 0.012
Reversibility: 0.00
</code></pre></div></div> <p>These metrics provide valuable insights into the tokenizer’s performance on the provided dataset.</p> <h2 id="evaluation-metrics">Evaluation Metrics</h2> <h3 id="usage-4">Usage</h3> <p>Next, navigate to the evaluation directory:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd eval
</code></pre></div></div> <p>You can run the <code class="language-plaintext highlighter-rouge">evaluation_metrics.py</code> script via:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python evaluation_metrics.py
</code></pre></div></div> <p>This script will load the babbelphish test dataset and perform a pass@k and BLEU score evaluation using a fine-tuned language model from OpenAI.</p> <h3 id="metrics">Metrics</h3> <p>The evaluation_metrics.py script evaluates the performance of the model using two metrics:</p> <p><em>pass@k</em>: This measures the proportion of test cases where the correct answer is within the model’s top ‘k’ predictions.</p> <p><em>BLEU</em>: This compares the model’s output to reference translations and scores the similarity, providing an indication of how closely the model’s output matches the expected output. It is computed on the top-ranked prediction.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Bobby Filar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>